{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Update the outdated pyg files\n",
    "import torch\n",
    "import torch_geometric\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bump(g):\n",
    "    return torch_geometric.data.data.Data.from_dict(g.__dict__)\n",
    "\n",
    "for file in tqdm(os.listdir('data/TCGA_GBMLGG/all_st_cpc_old')):\n",
    "    old = torch.load(os.path.join('data/TCGA_GBMLGG/all_st_cpc_old', file))\n",
    "    new = bump(old)\n",
    "    torch.save(new, os.path.join('data/TCGA_GBMLGG/all_st_cpc', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate VGG features for all patches\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from src.networks import get_vgg19\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "# Change this depending on task\n",
    "load_path = 'checkpoints/surv/path_instance'\n",
    "img_dir = 'data/path/patch'\n",
    "vgg_file = 'data/path/vgg_features_surv.pkl'\n",
    "\n",
    "# check file exists\n",
    "if os.path.exists(vgg_file):\n",
    "    with open(vgg_file, 'rb') as f:\n",
    "        vgg_dict = pickle.load(f)\n",
    "else:\n",
    "    vgg_dict = {}\n",
    "\n",
    "opt = argparse.Namespace(\n",
    "    mil=\"instance\",\n",
    "    attn_pool=0,\n",
    ")\n",
    "for ckpt in os.listdir(load_path):\n",
    "    ckpt_dict = {}\n",
    "    if 'path' in ckpt:\n",
    "        split = ckpt.split('_')[1].split('.')[0]\n",
    "        if split in vgg_dict:\n",
    "            print(f\"Skipping {split}\")\n",
    "            continue\n",
    "        model = get_vgg19(opt)\n",
    "        model_ckpt = torch.load(os.path.join(load_path, ckpt), map_location=device)\n",
    "        model.load_state_dict(model_ckpt['model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        for fname in tqdm(os.listdir(img_dir)):\n",
    "            x_path = Image.open(os.path.join(img_dir, fname)).convert('RGB')\n",
    "            tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "            x_path = torch.unsqueeze(tf(x_path), dim=0)\n",
    "            features, _,_ = model(x_path=x_path.to(device))\n",
    "            ckpt_dict[fname] = features.cpu().detach().numpy()\n",
    "\n",
    "        vgg_dict[split] = ckpt_dict\n",
    "        assert len(vgg_dict[split]) == len(os.listdir(img_dir))\n",
    "\n",
    "with open(vgg_file, 'wb') as f:  # Rename depending on task\n",
    "    pickle.dump(vgg_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing CoxLoss: over 400 times faster on CPU for a batch size of 64\n",
    "# Performance gains scale with batch size\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Paper's implementation\n",
    "def CoxLoss_old(survtime, censor, hazard_pred, device):\n",
    "    current_batch_len = len(survtime)\n",
    "    R_mat = np.zeros([current_batch_len, current_batch_len], dtype=int)\n",
    "    for i in range(current_batch_len):\n",
    "        for j in range(current_batch_len):\n",
    "            R_mat[i,j] = survtime[j] >= survtime[i]\n",
    "\n",
    "    R_mat = torch.FloatTensor(R_mat).to(device)\n",
    "    theta = hazard_pred.reshape(-1)\n",
    "    exp_theta = torch.exp(theta)\n",
    "    loss_cox = -torch.mean((theta - torch.log(torch.sum(exp_theta*R_mat, dim=1))) * censor)\n",
    "    return loss_cox\n",
    "\n",
    "\n",
    "# Optimized implementation\n",
    "def cox_loss(\n",
    "    survtime: torch.Tensor, event: torch.Tensor, hazard_pred: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Source: https://github.com/traversc/cox-nnet\"\"\"\n",
    "    # Predictions are not independent in Coxloss; calculating over batch != whole dataset\n",
    "    R_mat = (survtime.repeat(len(survtime), 1) >= survtime.unsqueeze(1)).int()\n",
    "    theta = hazard_pred.view(-1)\n",
    "    exp_theta = theta.exp()\n",
    "    loss_cox = -torch.mean((theta - (exp_theta * R_mat).sum(dim=1).log()) * event)\n",
    "    return loss_cox\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch = 64\n",
    "\n",
    "survtime = torch.rand(batch).to(device)\n",
    "censor = torch.randint(0, 2, (batch,)).to(device)\n",
    "hazard_pred = torch.rand(batch).to(device)\n",
    "assert CoxLoss_old(survtime, censor, hazard_pred, device) == cox_loss(survtime, censor, hazard_pred)\n",
    "\n",
    "%timeit CoxLoss_old(survtime, censor, hazard_pred, device)\n",
    "%timeit cox_loss(survtime, censor, hazard_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
